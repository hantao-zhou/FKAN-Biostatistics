{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA LOADING AND NORMALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 244\n",
    "\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Load and resize the image\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Resize the image\n",
    "                \n",
    "                # Add the image and label as a pair\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "    \n",
    "    # Convert the list to a NumPy array\n",
    "    data = np.array(data, dtype=object)  # Use dtype=object to allow image-label pairing\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "train_data = get_training_data('data/chest_xray/train')\n",
    "test_data = get_training_data('data/chest_xray/test')\n",
    "val_data = get_training_data('data/chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NORMALIZE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize the images\n",
    "def normalize_images(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for img, label in data:\n",
    "        # Normalization: each pixel is divided by 255\n",
    "        normalized_img = img / 255.0\n",
    "        images.append(normalized_img)\n",
    "        labels.append(label)\n",
    "\n",
    "#Convert the images and labels into separate arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized and shuffled train images: (6214, 244, 244)\n",
      "Shape of normalized and shuffled validation images: (1046, 244, 244)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the images in the training dataset\n",
    "train_images, train_labels = normalize_images(train_data)\n",
    "val_images, val_labels = normalize_images(val_data)\n",
    "test_images, test_labels = normalize_images(test_data)\n",
    "\n",
    "#Shuffle the training and validation data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "val_images, val_labels = shuffle(val_images, val_labels, random_state=42)\n",
    "\n",
    "#Check the shape and an example of the normalized and shuffled data\n",
    "print(f\"Shape of normalized and shuffled train images: {train_images.shape}\")\n",
    "print(f\"Shape of normalized and shuffled validation images: {val_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the images and the labels\n",
    "# train_images = np.array([x[0] for x in train_data])  # Extract only the images\n",
    "# train_labels = np.array([x[1] for x in train_data])  # Extract only the labels\n",
    "\n",
    "# # Display the first image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[0])  # The first image\n",
    "# plt.title('Pneumonia' if train_labels[0] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()\n",
    "\n",
    "# # Display the last image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[-1])  # The last image\n",
    "# plt.title('Pneumonia' if train_labels[-1] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN REAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 5]              15\n",
      "              ReLU-2                    [-1, 5]               0\n",
      "              ReLU-3                    [-1, 5]               0\n",
      "            Linear-4                    [-1, 2]              12\n",
      "================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import shuffle  # Assuming 'shuffle' is needed for shuffling data\n",
    "from kan import * #Here I used a original KAN implentation from https://github.com/KindXiaoming/pykan/blob/master/hellokan.ipynb\n",
    "\n",
    "\n",
    "\n",
    "# Use PCA to reduce dimensionality to 2D\n",
    "def apply_pca(images, n_components=2):\n",
    "    flat_images = images.reshape(images.shape[0], -1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_images = pca.fit_transform(flat_images)\n",
    "    return transformed_images\n",
    "\n",
    "# Dummy data creation for sample\n",
    "train_images = np.random.random((100, 28, 28))\n",
    "val_images = np.random.random((20, 28, 28))\n",
    "test_images = np.random.random((20, 28, 28))\n",
    "train_labels = np.random.randint(0, 2, 100)\n",
    "val_labels = np.random.randint(0, 2, 20)\n",
    "\n",
    "# Apply PCA to get 2D vectors\n",
    "train_images_pca = apply_pca(train_images)\n",
    "val_images_pca = apply_pca(val_images)\n",
    "test_images_pca = apply_pca(test_images)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_tensors = torch.tensor(train_images_pca, dtype=torch.float32)\n",
    "train_labels_tensors = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_tensors = torch.tensor(val_images_pca, dtype=torch.float32)\n",
    "val_labels_tensors = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_tensors, train_labels_tensors)\n",
    "val_dataset = TensorDataset(val_tensors, val_labels_tensors)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class KAN_Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=[128, 64], output_dim=2, polynomial_order=3, activation=nn.ReLU):\n",
    "        super(KAN_Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.polynomial_order = polynomial_order\n",
    "        self.activation = activation()\n",
    "\n",
    "        poly_feature_size = (self.polynomial_order + 1) * self.input_dim\n",
    "\n",
    "        # Define layers\n",
    "        self.base_layers = nn.ModuleList()\n",
    "        in_dim = self.input_dim\n",
    "        for dim in hidden_dim:\n",
    "            self.base_layers.append(nn.Linear(in_dim, dim))\n",
    "            in_dim = dim\n",
    "\n",
    "        self.poly_weights = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(dim, poly_feature_size)) for dim in hidden_dim\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(in_dim, output_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        for layer in self.base_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight, nonlinearity='linear')\n",
    "        for weight in self.poly_weights:\n",
    "            nn.init.kaiming_uniform_(weight, nonlinearity='linear')\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_legendre_polynomials(x, order):\n",
    "        P0 = torch.ones_like(x)\n",
    "        P1 = x\n",
    "        legendre_polys = [P0, P1]\n",
    "\n",
    "        for n in range(1, order):\n",
    "            Pn = ((2.0 * n + 1.0) * x * legendre_polys[-1] - n * legendre_polys[-2]) / (n + 1.0)\n",
    "            legendre_polys.append(Pn)\n",
    "        \n",
    "        return torch.cat(legendre_polys, dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Update this line\n",
    "\n",
    "        for layer, poly_weight in zip(self.base_layers, self.poly_weights):\n",
    "            base_output = self.activation(layer(x))\n",
    "\n",
    "            # Normalize x for Legendre polynomials\n",
    "            x_min = x.min(dim=1, keepdim=True)[0]\n",
    "            x_max = x.max(dim=1, keepdim=True)[0]\n",
    "            x_normalized = 2 * (x - x_min) / (x_max - x_min) - 1\n",
    "            legendre_basis = self.compute_legendre_polynomials(x_normalized.unsqueeze(-1), self.polynomial_order)\n",
    "\n",
    "            legendre_basis = legendre_basis.view(x.size(0), -1)  # Flatten the Legendre basis\n",
    "\n",
    "            if legendre_basis.shape[1] != poly_weight.shape[1]:\n",
    "                raise RuntimeError(\n",
    "                    f\"Legendre basis dimension {legendre_basis.shape[1]} does not match poly_weight dimension {poly_weight.shape[1]}\"\n",
    "                )\n",
    "\n",
    "            poly_output = torch.matmul(legendre_basis, poly_weight.T)\n",
    "            x = self.activation(base_output + poly_output)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x  # Return logits directly, no softmax\n",
    "\n",
    "# Setup and model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def initialize_kan_net(width, seed, device):\n",
    "    torch.manual_seed(seed)\n",
    "    input_dim = width[0]\n",
    "    hidden_dim = width[1:]\n",
    "    model = KAN_Net(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=2)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model = initialize_kan_net(width=[2, 5], seed=42, device=device)\n",
    "\n",
    "# Print a model summary\n",
    "summary(model, (2,))\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 0.6795, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9571, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 2/100\n",
      "Train Loss: 0.6792, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9574, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 3/100\n",
      "Train Loss: 0.6790, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9571, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 4/100\n",
      "Train Loss: 0.6789, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9572, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 5/100\n",
      "Train Loss: 0.6786, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9575, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 6/100\n",
      "Train Loss: 0.6784, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9570, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 7/100\n",
      "Train Loss: 0.6783, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9572, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 8/100\n",
      "Train Loss: 0.6781, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9566, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 9/100\n",
      "Train Loss: 0.6780, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9562, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 10/100\n",
      "Train Loss: 0.6778, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9564, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 11/100\n",
      "Train Loss: 0.6777, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9562, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 12/100\n",
      "Train Loss: 0.6776, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9560, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 13/100\n",
      "Train Loss: 0.6773, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9561, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 14/100\n",
      "Train Loss: 0.6772, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9559, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 15/100\n",
      "Train Loss: 0.6771, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9559, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Model saved!\n",
      "Epoch 16/100\n",
      "Train Loss: 0.6769, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9561, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 1/10\n",
      "Epoch 17/100\n",
      "Train Loss: 0.6768, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9564, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 2/10\n",
      "Epoch 18/100\n",
      "Train Loss: 0.6766, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9565, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 3/10\n",
      "Epoch 19/100\n",
      "Train Loss: 0.6765, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9566, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 4/10\n",
      "Epoch 20/100\n",
      "Train Loss: 0.6763, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9565, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 5/10\n",
      "Epoch 21/100\n",
      "Train Loss: 0.6763, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9565, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 6/10\n",
      "Epoch 22/100\n",
      "Train Loss: 0.6761, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9567, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 7/10\n",
      "Epoch 23/100\n",
      "Train Loss: 0.6760, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.9564, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 8/10\n",
      "Epoch 24/100\n",
      "Train Loss: 0.6759, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9565, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.5294, Validation Recall: 0.7500\n",
      "Early Stopping Counter: 9/10\n",
      "Epoch 25/100\n",
      "Train Loss: 0.6757, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.9568, Validation Accuracy: 0.4000\n",
      "Validation Precision: 0.5000, Validation Recall: 0.6667\n",
      "Early Stopping Counter: 10/10\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "python\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Apply the transformation to training and validation images\n",
    "train_images_tensor = torch.tensor(train_images_pca)\n",
    "val_images_tensor = torch.tensor(val_images_pca)\n",
    "\n",
    "# The tensors are already in the shape (N, 2) after PCA\n",
    "\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long) \n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long) \n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "\n",
    "# Define the batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Model and device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class or binary classification\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)  \n",
    "\n",
    "# Now the data is ready for training and validation\n",
    "\n",
    "# Function to calculate precision and recall\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Training function with Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0  # Count the number of epochs without improvement\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Training mode\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute metrics\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Calculate precision and recall on validation\n",
    "        val_precision, val_recall = calculate_precision_recall(model, val_loader, device)\n",
    "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Early Stopping: stop if no improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the model with the best validation loss\n",
    "            torch.save(model.state_dict(), \"best_model_v3.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "        # If the number of epochs without improvement exceeds patience, stop\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Start training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6000\n",
      "Test Precision: 0.6667\n",
      "Test Recall: 0.7692\n",
      "Test F1-Score: 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rateb\\AppData\\Local\\Temp\\ipykernel_40564\\2486844566.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_v3.pth\"))\n"
     ]
    }
   ],
   "source": [
    "python\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Correctly use test_images_pca for testing\n",
    "test_labels = np.random.randint(0, 2, 20)  # Ensure test_labels is defined\n",
    "test_images_tensor = torch.tensor(test_images_pca, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Adjust the length of test_labels to match test_images_pca\n",
    "if len(test_labels_tensor) != len(test_images_tensor):\n",
    "    test_labels_tensor = test_labels_tensor[:len(test_images_tensor)]\n",
    "\n",
    "# Create the dataset and DataLoader for the test set\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "def calculate_metrics(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            correct_preds += torch.sum(preds == target).item()\n",
    "            total_preds += target.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    precision, recall, f1, accuracy = calculate_metrics(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "\n",
    "model = initialize_kan_net(width=[2, 5], seed=42, device=device)\n",
    "model.load_state_dict(torch.load(\"best_model_v3.pth\"))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
