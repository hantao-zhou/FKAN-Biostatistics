{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA LOADING AND NORMALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 244\n",
    "\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Load and resize the image\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Resize the image\n",
    "                \n",
    "                # Add the image and label as a pair\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "    \n",
    "    # Convert the list to a NumPy array\n",
    "    data = np.array(data, dtype=object)  # Use dtype=object to allow image-label pairing\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "train_data = get_training_data('data/chest_xray/train')\n",
    "test_data = get_training_data('data/chest_xray/test')\n",
    "val_data = get_training_data('data/chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NORMALIZE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize the images\n",
    "def normalize_images(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for img, label in data:\n",
    "        # Normalization: each pixel is divided by 255\n",
    "        normalized_img = img / 255.0\n",
    "        images.append(normalized_img)\n",
    "        labels.append(label)\n",
    "\n",
    "#Convert the images and labels into separate arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized and shuffled train images: (6214, 244, 244)\n",
      "Shape of normalized and shuffled validation images: (1046, 244, 244)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the images in the training dataset\n",
    "train_images, train_labels = normalize_images(train_data)\n",
    "val_images, val_labels = normalize_images(val_data)\n",
    "test_images, test_labels = normalize_images(test_data)\n",
    "\n",
    "#Shuffle the training and validation data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "val_images, val_labels = shuffle(val_images, val_labels, random_state=42)\n",
    "\n",
    "#Check the shape and an example of the normalized and shuffled data\n",
    "print(f\"Shape of normalized and shuffled train images: {train_images.shape}\")\n",
    "print(f\"Shape of normalized and shuffled validation images: {val_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the images and the labels\n",
    "# train_images = np.array([x[0] for x in train_data])  # Extract only the images\n",
    "# train_labels = np.array([x[1] for x in train_data])  # Extract only the labels\n",
    "\n",
    "# # Display the first image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[0])  # The first image\n",
    "# plt.title('Pneumonia' if train_labels[0] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()\n",
    "\n",
    "# # Display the last image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[-1])  # The last image\n",
    "# plt.title('Pneumonia' if train_labels[-1] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN REAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 5]              15\n",
      "              ReLU-2                    [-1, 5]               0\n",
      "              ReLU-3                    [-1, 5]               0\n",
      "            Linear-4                    [-1, 2]              12\n",
      "================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import shuffle  # Assuming 'shuffle' is needed for shuffling data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use PCA to reduce dimensionality to 2D\n",
    "def apply_pca(images, n_components=2):\n",
    "    flat_images = images.reshape(images.shape[0], -1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_images = pca.fit_transform(flat_images)\n",
    "    return transformed_images\n",
    "\n",
    "# Dummy data creation for sample\n",
    "train_images = np.random.random((100, 28, 28))\n",
    "val_images = np.random.random((20, 28, 28))\n",
    "test_images = np.random.random((20, 28, 28))\n",
    "train_labels = np.random.randint(0, 2, 100)\n",
    "val_labels = np.random.randint(0, 2, 20)\n",
    "\n",
    "# Apply PCA to get 2D vectors\n",
    "train_images_pca = apply_pca(train_images)\n",
    "val_images_pca = apply_pca(val_images)\n",
    "test_images_pca = apply_pca(test_images)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_tensors = torch.tensor(train_images_pca, dtype=torch.float32)\n",
    "train_labels_tensors = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_tensors = torch.tensor(val_images_pca, dtype=torch.float32)\n",
    "val_labels_tensors = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_tensors, train_labels_tensors)\n",
    "val_dataset = TensorDataset(val_tensors, val_labels_tensors)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class KAN_Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=[128, 64], output_dim=2, polynomial_order=3, activation=nn.ReLU):\n",
    "        super(KAN_Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.polynomial_order = polynomial_order\n",
    "        self.activation = activation()\n",
    "\n",
    "        poly_feature_size = (self.polynomial_order + 1) * self.input_dim\n",
    "\n",
    "        # Define layers\n",
    "        self.base_layers = nn.ModuleList()\n",
    "        in_dim = self.input_dim\n",
    "        for dim in hidden_dim:\n",
    "            self.base_layers.append(nn.Linear(in_dim, dim))\n",
    "            in_dim = dim\n",
    "\n",
    "        self.poly_weights = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(dim, poly_feature_size)) for dim in hidden_dim\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(in_dim, output_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        for layer in self.base_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight, nonlinearity='linear')\n",
    "        for weight in self.poly_weights:\n",
    "            nn.init.kaiming_uniform_(weight, nonlinearity='linear')\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_legendre_polynomials(x, order):\n",
    "        P0 = torch.ones_like(x)\n",
    "        P1 = x\n",
    "        legendre_polys = [P0, P1]\n",
    "\n",
    "        for n in range(1, order):\n",
    "            Pn = ((2.0 * n + 1.0) * x * legendre_polys[-1] - n * legendre_polys[-2]) / (n + 1.0)\n",
    "            legendre_polys.append(Pn)\n",
    "        \n",
    "        return torch.cat(legendre_polys, dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "\n",
    "        for layer, poly_weight in zip(self.base_layers, self.poly_weights):\n",
    "            base_output = self.activation(layer(x))\n",
    "\n",
    "            # Normalize x for Legendre polynomials\n",
    "            x_min = x.min(dim=1, keepdim=True)[0]\n",
    "            x_max = x.max(dim=1, keepdim=True)[0]\n",
    "            x_normalized = 2 * (x - x_min) / (x_max - x_min) - 1\n",
    "            legendre_basis = self.compute_legendre_polynomials(x_normalized.unsqueeze(-1), self.polynomial_order)\n",
    "\n",
    "            legendre_basis = legendre_basis.view(x.size(0), -1)  # Flatten the Legendre basis\n",
    "\n",
    "            if legendre_basis.shape[1] != poly_weight.shape[1]:\n",
    "                raise RuntimeError(\n",
    "                    f\"Legendre basis dimension {legendre_basis.shape[1]} does not match poly_weight dimension {poly_weight.shape[1]}\"\n",
    "                )\n",
    "\n",
    "            poly_output = torch.matmul(legendre_basis, poly_weight.T)\n",
    "            x = self.activation(base_output + poly_output)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x  # Return logits directly, no softmax\n",
    "\n",
    "# Setup and model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def initialize_kan_net(width, seed, device):\n",
    "    torch.manual_seed(seed)\n",
    "    input_dim = width[0]\n",
    "    hidden_dim = width[1:]\n",
    "    model = KAN_Net(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=2)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model = initialize_kan_net(width=[2, 5], seed=42, device=device)\n",
    "\n",
    "# Print a model summary\n",
    "summary(model, (2,))\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 0.7743, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.8075, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 2/100\n",
      "Train Loss: 0.7727, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.8050, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 3/100\n",
      "Train Loss: 0.7711, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.8027, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 4/100\n",
      "Train Loss: 0.7695, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.8007, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 5/100\n",
      "Train Loss: 0.7682, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7986, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 6/100\n",
      "Train Loss: 0.7666, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7963, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 1.0000\n",
      "Model saved!\n",
      "Epoch 7/100\n",
      "Train Loss: 0.7650, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7937, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 8/100\n",
      "Train Loss: 0.7632, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7915, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 9/100\n",
      "Train Loss: 0.7617, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7893, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 10/100\n",
      "Train Loss: 0.7605, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7871, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 11/100\n",
      "Train Loss: 0.7591, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7850, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 12/100\n",
      "Train Loss: 0.7579, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7829, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 13/100\n",
      "Train Loss: 0.7564, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7812, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 14/100\n",
      "Train Loss: 0.7554, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7790, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 15/100\n",
      "Train Loss: 0.7540, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7771, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 16/100\n",
      "Train Loss: 0.7527, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7754, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4706, Validation Recall: 0.8889\n",
      "Model saved!\n",
      "Epoch 17/100\n",
      "Train Loss: 0.7515, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7735, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 18/100\n",
      "Train Loss: 0.7504, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7713, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 19/100\n",
      "Train Loss: 0.7492, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7694, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 20/100\n",
      "Train Loss: 0.7480, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7677, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 21/100\n",
      "Train Loss: 0.7469, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7659, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 22/100\n",
      "Train Loss: 0.7458, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7640, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 23/100\n",
      "Train Loss: 0.7447, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7624, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 24/100\n",
      "Train Loss: 0.7436, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7606, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4375, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 25/100\n",
      "Train Loss: 0.7425, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7589, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 26/100\n",
      "Train Loss: 0.7414, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7571, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 27/100\n",
      "Train Loss: 0.7404, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7554, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 28/100\n",
      "Train Loss: 0.7393, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7536, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 29/100\n",
      "Train Loss: 0.7381, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7518, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 30/100\n",
      "Train Loss: 0.7370, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7500, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 31/100\n",
      "Train Loss: 0.7357, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7474, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 32/100\n",
      "Train Loss: 0.7340, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7450, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 33/100\n",
      "Train Loss: 0.7323, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7426, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 34/100\n",
      "Train Loss: 0.7309, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7402, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4667, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 35/100\n",
      "Train Loss: 0.7293, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7380, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 36/100\n",
      "Train Loss: 0.7278, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7357, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 37/100\n",
      "Train Loss: 0.7265, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7330, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 38/100\n",
      "Train Loss: 0.7248, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7309, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 39/100\n",
      "Train Loss: 0.7234, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7286, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 40/100\n",
      "Train Loss: 0.7220, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.7268, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 41/100\n",
      "Train Loss: 0.7208, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7246, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 42/100\n",
      "Train Loss: 0.7195, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.7229, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 43/100\n",
      "Train Loss: 0.7184, Train Accuracy: 0.4200\n",
      "Validation Loss: 0.7207, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 44/100\n",
      "Train Loss: 0.7171, Train Accuracy: 0.4300\n",
      "Validation Loss: 0.7186, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 45/100\n",
      "Train Loss: 0.7160, Train Accuracy: 0.4300\n",
      "Validation Loss: 0.7166, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 46/100\n",
      "Train Loss: 0.7146, Train Accuracy: 0.4300\n",
      "Validation Loss: 0.7151, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 47/100\n",
      "Train Loss: 0.7136, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7134, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 48/100\n",
      "Train Loss: 0.7125, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7120, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 49/100\n",
      "Train Loss: 0.7116, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7100, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 50/100\n",
      "Train Loss: 0.7105, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7082, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 51/100\n",
      "Train Loss: 0.7092, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7068, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 52/100\n",
      "Train Loss: 0.7084, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7050, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 53/100\n",
      "Train Loss: 0.7073, Train Accuracy: 0.4100\n",
      "Validation Loss: 0.7035, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 54/100\n",
      "Train Loss: 0.7062, Train Accuracy: 0.4300\n",
      "Validation Loss: 0.7020, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 55/100\n",
      "Train Loss: 0.7055, Train Accuracy: 0.4300\n",
      "Validation Loss: 0.7001, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 56/100\n",
      "Train Loss: 0.7043, Train Accuracy: 0.4400\n",
      "Validation Loss: 0.6988, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 57/100\n",
      "Train Loss: 0.7032, Train Accuracy: 0.4400\n",
      "Validation Loss: 0.6978, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 58/100\n",
      "Train Loss: 0.7027, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6957, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 59/100\n",
      "Train Loss: 0.7013, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6946, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 60/100\n",
      "Train Loss: 0.7007, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6931, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 61/100\n",
      "Train Loss: 0.6996, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6919, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 62/100\n",
      "Train Loss: 0.6989, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6906, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 63/100\n",
      "Train Loss: 0.6981, Train Accuracy: 0.4500\n",
      "Validation Loss: 0.6893, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 64/100\n",
      "Train Loss: 0.6972, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6883, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 65/100\n",
      "Train Loss: 0.6965, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6874, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 66/100\n",
      "Train Loss: 0.6959, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6862, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 67/100\n",
      "Train Loss: 0.6951, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6853, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 68/100\n",
      "Train Loss: 0.6945, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6839, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 69/100\n",
      "Train Loss: 0.6936, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6833, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 70/100\n",
      "Train Loss: 0.6931, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6820, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 71/100\n",
      "Train Loss: 0.6923, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6811, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 72/100\n",
      "Train Loss: 0.6916, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6799, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 73/100\n",
      "Train Loss: 0.6909, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6788, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 74/100\n",
      "Train Loss: 0.6901, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6778, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 75/100\n",
      "Train Loss: 0.6895, Train Accuracy: 0.4600\n",
      "Validation Loss: 0.6766, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 76/100\n",
      "Train Loss: 0.6888, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6755, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 77/100\n",
      "Train Loss: 0.6880, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6745, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 78/100\n",
      "Train Loss: 0.6874, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6735, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 79/100\n",
      "Train Loss: 0.6868, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6728, Validation Accuracy: 0.5500\n",
      "Validation Precision: 0.5000, Validation Recall: 0.7778\n",
      "Model saved!\n",
      "Epoch 80/100\n",
      "Train Loss: 0.6862, Train Accuracy: 0.4700\n",
      "Validation Loss: 0.6722, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 81/100\n",
      "Train Loss: 0.6858, Train Accuracy: 0.5100\n",
      "Validation Loss: 0.6713, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 82/100\n",
      "Train Loss: 0.6852, Train Accuracy: 0.5200\n",
      "Validation Loss: 0.6706, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 83/100\n",
      "Train Loss: 0.6848, Train Accuracy: 0.5100\n",
      "Validation Loss: 0.6697, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 84/100\n",
      "Train Loss: 0.6841, Train Accuracy: 0.5100\n",
      "Validation Loss: 0.6691, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 85/100\n",
      "Train Loss: 0.6837, Train Accuracy: 0.5100\n",
      "Validation Loss: 0.6682, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 86/100\n",
      "Train Loss: 0.6831, Train Accuracy: 0.5100\n",
      "Validation Loss: 0.6675, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 87/100\n",
      "Train Loss: 0.6826, Train Accuracy: 0.5200\n",
      "Validation Loss: 0.6670, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4615, Validation Recall: 0.6667\n",
      "Model saved!\n",
      "Epoch 88/100\n",
      "Train Loss: 0.6821, Train Accuracy: 0.5200\n",
      "Validation Loss: 0.6664, Validation Accuracy: 0.4500\n",
      "Validation Precision: 0.4167, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 89/100\n",
      "Train Loss: 0.6816, Train Accuracy: 0.5300\n",
      "Validation Loss: 0.6656, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 90/100\n",
      "Train Loss: 0.6812, Train Accuracy: 0.5300\n",
      "Validation Loss: 0.6650, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 91/100\n",
      "Train Loss: 0.6807, Train Accuracy: 0.5400\n",
      "Validation Loss: 0.6645, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 92/100\n",
      "Train Loss: 0.6802, Train Accuracy: 0.5400\n",
      "Validation Loss: 0.6639, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 93/100\n",
      "Train Loss: 0.6798, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.6634, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 94/100\n",
      "Train Loss: 0.6795, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.6626, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 95/100\n",
      "Train Loss: 0.6788, Train Accuracy: 0.5500\n",
      "Validation Loss: 0.6621, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 96/100\n",
      "Train Loss: 0.6784, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.6617, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 97/100\n",
      "Train Loss: 0.6781, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.6609, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 98/100\n",
      "Train Loss: 0.6777, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.6603, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 99/100\n",
      "Train Loss: 0.6772, Train Accuracy: 0.5700\n",
      "Validation Loss: 0.6601, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n",
      "Epoch 100/100\n",
      "Train Loss: 0.6768, Train Accuracy: 0.5700\n",
      "Validation Loss: 0.6597, Validation Accuracy: 0.5000\n",
      "Validation Precision: 0.4545, Validation Recall: 0.5556\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Apply the transformation to training and validation images\n",
    "train_images_tensor = torch.tensor(train_images_pca)\n",
    "val_images_tensor = torch.tensor(val_images_pca)\n",
    "\n",
    "# The tensors are already in the shape (N, 2) after PCA\n",
    "\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long) \n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long) \n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "\n",
    "# Define the batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Model and device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class or binary classification\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)  \n",
    "\n",
    "# Now the data is ready for training and validation\n",
    "\n",
    "# Function to calculate precision and recall\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Training function with Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0  # Count the number of epochs without improvement\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Training mode\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute metrics\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Calculate precision and recall on validation\n",
    "        val_precision, val_recall = calculate_precision_recall(model, val_loader, device)\n",
    "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Early Stopping: stop if no improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the model with the best validation loss\n",
    "            torch.save(model.state_dict(), \"best_model_v3.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "        # If the number of epochs without improvement exceeds patience, stop\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Start training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5000\n",
      "Test Precision: 0.6000\n",
      "Test Recall: 0.5000\n",
      "Test F1-Score: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rateb\\AppData\\Local\\Temp\\ipykernel_40564\\2486844566.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_v3.pth\"))\n"
     ]
    }
   ],
   "source": [
    "python\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Correctly use test_images_pca for testing\n",
    "test_labels = np.random.randint(0, 2, 20)  # Ensure test_labels is defined\n",
    "test_images_tensor = torch.tensor(test_images_pca, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Adjust the length of test_labels to match test_images_pca\n",
    "if len(test_labels_tensor) != len(test_images_tensor):\n",
    "    test_labels_tensor = test_labels_tensor[:len(test_images_tensor)]\n",
    "\n",
    "# Create the dataset and DataLoader for the test set\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "def calculate_metrics(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            correct_preds += torch.sum(preds == target).item()\n",
    "            total_preds += target.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    precision, recall, f1, accuracy = calculate_metrics(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "\n",
    "model = initialize_kan_net(width=[2, 5], seed=42, device=device)\n",
    "model.load_state_dict(torch.load(\"best_model_v3.pth\"))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
