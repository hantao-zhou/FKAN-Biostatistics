{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assumiamo che i tuoi dati siano già in formato numpy e normalizzati tra 0 e 1\n",
    "# Carica i dati come tensori\n",
    "images_tensor = torch.tensor(augmented_train_images_normalized, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(augmented_train_labels, dtype=torch.long)\n",
    "\n",
    "# Aggiungi una dimensione per il canale (1 canale per immagini in scala di grigio)\n",
    "images_tensor = images_tensor.unsqueeze(1)  # Shape: (7750, 1, 150, 150)\n",
    "images_tensor = images_tensor.squeeze(-1)\n",
    "print(images_tensor.shape)\n",
    "\n",
    "# Splitta i dati in 80% training e 20% validazione (stratificato)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(images_tensor, labels_tensor))\n",
    "\n",
    "train_images_tensor = images_tensor[train_idx]\n",
    "val_images_tensor = images_tensor[val_idx]\n",
    "\n",
    "train_labels_tensor = labels_tensor[train_idx]\n",
    "val_labels_tensor = labels_tensor[val_idx]\n",
    "\n",
    "# Crea i dataset e DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modello e device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvNeXtKAN().to(device)\n",
    "\n",
    "# Definizione della funzione di perdita e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss()  # Per classificazione multi-classe o binaria\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Informazioni sugli split\n",
    "print(f\"Train set: {len(train_dataset)} samples\")\n",
    "print(f\"Validation set: {len(val_dataset)} samples\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0  # Conta quante epoche senza miglioramento\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modalità allenamento\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Azzeramento dei gradienti\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calcolo della perdita\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calcolo delle metriche\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        # Calcolo della loss media e accuratezza\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Fase di validazione\n",
    "        model.eval()  # Modalità valutazione\n",
    "        val_loss = 0.0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Calcolo della perdita\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calcolo delle metriche\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        # Calcolo della loss e accuratezza di validazione\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Early Stopping: fermarsi se non c'è miglioramento\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_accuracy = val_accuracy\n",
    "            epochs_without_improvement = 0\n",
    "            # Salva il modello con la miglior loss di validazione\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "        # Se il numero di epoche senza miglioramenti supera la pazienza, fermati\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Avvia l'allenamento\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
