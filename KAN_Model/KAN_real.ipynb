{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA LOADING AND NORMALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 224\n",
    "\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Load and resize the image\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Resize the image\n",
    "                \n",
    "                # Add the image and label as a pair\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "    \n",
    "    # Convert the list to a NumPy array\n",
    "    data = np.array(data, dtype=object)  # Use dtype=object to allow image-label pairing\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "train_data = get_training_data('data/chest_xray/train')\n",
    "test_data = get_training_data('data/chest_xray/test')\n",
    "val_data = get_training_data('data/chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NORMALIZE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize the images\n",
    "def normalize_images(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for img, label in data:\n",
    "        # Normalization: each pixel is divided by 255\n",
    "        normalized_img = img / 255.0\n",
    "        images.append(normalized_img)\n",
    "        labels.append(label)\n",
    "\n",
    "#Convert the images and labels into separate arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized and shuffled train images: (6214, 224, 224)\n",
      "Shape of normalized and shuffled validation images: (1046, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the images in the training dataset\n",
    "train_images, train_labels = normalize_images(train_data)\n",
    "val_images, val_labels = normalize_images(val_data)\n",
    "test_images, test_labels = normalize_images(test_data)\n",
    "\n",
    "#Shuffle the training and validation data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "val_images, val_labels = shuffle(val_images, val_labels, random_state=42)\n",
    "\n",
    "#Check the shape and an example of the normalized and shuffled data\n",
    "print(f\"Shape of normalized and shuffled train images: {train_images.shape}\")\n",
    "print(f\"Shape of normalized and shuffled validation images: {val_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the images and the labels\n",
    "# train_images = np.array([x[0] for x in train_data])  # Extract only the images\n",
    "# train_labels = np.array([x[1] for x in train_data])  # Extract only the labels\n",
    "\n",
    "# # Display the first image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[0])  # The first image\n",
    "# plt.title('Pneumonia' if train_labels[0] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()\n",
    "\n",
    "# # Display the last image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train_images[-1])  # The last image\n",
    "# plt.title('Pneumonia' if train_labels[-1] == 0 else 'Normal')  # Set the title based on the label\n",
    "# plt.axis('off')  # To hide the axes\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN REAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Function to flatten images\n",
    "def flatten_images(images):\n",
    "    return torch.flatten(images, start_dim=1)\n",
    "\n",
    "\n",
    "train_images_tensor = torch.tensor(train_images)\n",
    "val_images_tensor = torch.tensor(val_images)\n",
    "test_images_tensor = torch.tensor(test_images)\n",
    "\n",
    "train_images_flat = flatten_images(train_images_tensor)\n",
    "val_images_flat = flatten_images(val_images_tensor)\n",
    "test_images_flat = flatten_images(test_images_tensor)\n",
    "\n",
    "train_labels_tensors = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_labels_tensors = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_images_flat, train_labels_tensors)\n",
    "val_dataset = TensorDataset(val_images_flat, val_labels_tensors)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class KAN_Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=[128, 64], output_dim=2, polynomial_order=3, activation=nn.ReLU):\n",
    "        super(KAN_Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.polynomial_order = polynomial_order\n",
    "        self.activation = activation()\n",
    "\n",
    "        poly_feature_size = (self.polynomial_order + 1) * self.input_dim\n",
    "\n",
    "        self.base_layers = nn.ModuleList()\n",
    "        in_dim = self.input_dim\n",
    "        for dim in hidden_dim:\n",
    "            self.base_layers.append(nn.Linear(in_dim, dim))\n",
    "            in_dim = dim\n",
    "\n",
    "        self.poly_weights = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(dim, poly_feature_size)) for dim in hidden_dim\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(in_dim, output_dim)\n",
    "\n",
    "        for layer in self.base_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight, nonlinearity='linear')\n",
    "        for weight in self.poly_weights:\n",
    "            nn.init.kaiming_uniform_(weight, nonlinearity='linear')\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_legendre_polynomials(x, order):\n",
    "        P0 = torch.ones_like(x)\n",
    "        P1 = x\n",
    "        legendre_polys = [P0, P1]\n",
    "\n",
    "        for n in range(1, order):\n",
    "            Pn = ((2.0 * n + 1.0) * x * legendre_polys[-1] - n * legendre_polys[-2]) / (n + 1.0)\n",
    "            legendre_polys.append(Pn)\n",
    "        \n",
    "        return torch.cat(legendre_polys, dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        for layer, poly_weight in zip(self.base_layers, self.poly_weights):\n",
    "            base_output = self.activation(layer(x))\n",
    "\n",
    "            x_min = x.min(dim=1, keepdim=True)[0]\n",
    "            x_max = x.max(dim=1, keepdim=True)[0]\n",
    "            x_normalized = 2 * (x - x_min) / (x_max - x_min) - 1\n",
    "            legendre_basis = self.compute_legendre_polynomials(x_normalized.unsqueeze(-1), self.polynomial_order)\n",
    "\n",
    "            legendre_basis = legendre_basis.view(x.size(0), -1)  # Reshape to match poly_weight expectations\n",
    "\n",
    "            # Adjust the dimension of the Legendre basis to match the poly_weight dimension\n",
    "            if legendre_basis.shape[1] != poly_weight.shape[1]:\n",
    "                legendre_basis = F.interpolate(legendre_basis.unsqueeze(1), size=(poly_weight.shape[1],), mode='linear', align_corners=False).squeeze(1)\n",
    "\n",
    "            poly_output = torch.matmul(legendre_basis, poly_weight.T)\n",
    "            x = self.activation(base_output + poly_output)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Setup and model initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def initialize_kan_net(width, seed, device):\n",
    "    torch.manual_seed(seed)\n",
    "    input_dim = width[0]\n",
    "    hidden_dim = width[1:]\n",
    "    model = KAN_Net(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=2)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "input_width = 224 * 224\n",
    "model = initialize_kan_net(width=[input_width, 128, 64], seed=42, device=device)\n",
    "\n",
    "# Removed torchsummary import and summary call\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 0.3642, Train Accuracy: 0.9071\n",
      "Validation Loss: 0.7255, Validation Accuracy: 0.8757\n",
      "Validation Precision: 0.9795, Validation Recall: 0.5296\n",
      "Model saved!\n",
      "Epoch 2/50\n",
      "Train Loss: 0.3147, Train Accuracy: 0.9285\n",
      "Validation Loss: 0.2304, Validation Accuracy: 0.9417\n",
      "Validation Precision: 0.8495, Validation Recall: 0.9407\n",
      "Model saved!\n",
      "Epoch 3/50\n",
      "Train Loss: 0.2375, Train Accuracy: 0.9421\n",
      "Validation Loss: 0.5740, Validation Accuracy: 0.9101\n",
      "Validation Precision: 0.9783, Validation Recall: 0.6667\n",
      "Early Stopping Counter: 1/5\n",
      "Epoch 4/50\n",
      "Train Loss: 0.2534, Train Accuracy: 0.9427\n",
      "Validation Loss: 0.3844, Validation Accuracy: 0.9216\n",
      "Validation Precision: 0.7749, Validation Recall: 0.9815\n",
      "Early Stopping Counter: 2/5\n",
      "Epoch 5/50\n",
      "Train Loss: 0.2289, Train Accuracy: 0.9474\n",
      "Validation Loss: 0.2871, Validation Accuracy: 0.9359\n",
      "Validation Precision: 0.8142, Validation Recall: 0.9741\n",
      "Early Stopping Counter: 3/5\n",
      "Epoch 6/50\n",
      "Train Loss: 0.2022, Train Accuracy: 0.9541\n",
      "Validation Loss: 0.2466, Validation Accuracy: 0.9560\n",
      "Validation Precision: 0.9706, Validation Recall: 0.8556\n",
      "Early Stopping Counter: 4/5\n",
      "Epoch 7/50\n",
      "Train Loss: 0.1585, Train Accuracy: 0.9586\n",
      "Validation Loss: 0.1602, Validation Accuracy: 0.9608\n",
      "Validation Precision: 0.9387, Validation Recall: 0.9074\n",
      "Model saved!\n",
      "Epoch 8/50\n",
      "Train Loss: 0.1148, Train Accuracy: 0.9683\n",
      "Validation Loss: 0.1490, Validation Accuracy: 0.9589\n",
      "Validation Precision: 0.9633, Validation Recall: 0.8741\n",
      "Model saved!\n",
      "Epoch 9/50\n",
      "Train Loss: 0.1443, Train Accuracy: 0.9627\n",
      "Validation Loss: 0.3150, Validation Accuracy: 0.9293\n",
      "Validation Precision: 0.9757, Validation Recall: 0.7444\n",
      "Early Stopping Counter: 1/5\n",
      "Epoch 10/50\n",
      "Train Loss: 0.0826, Train Accuracy: 0.9725\n",
      "Validation Loss: 0.1077, Validation Accuracy: 0.9685\n",
      "Validation Precision: 0.9405, Validation Recall: 0.9370\n",
      "Model saved!\n",
      "Epoch 11/50\n",
      "Train Loss: 0.0768, Train Accuracy: 0.9771\n",
      "Validation Loss: 0.1928, Validation Accuracy: 0.9455\n",
      "Validation Precision: 0.8424, Validation Recall: 0.9704\n",
      "Early Stopping Counter: 1/5\n",
      "Epoch 12/50\n",
      "Train Loss: 0.0760, Train Accuracy: 0.9743\n",
      "Validation Loss: 0.3803, Validation Accuracy: 0.9120\n",
      "Validation Precision: 0.7528, Validation Recall: 0.9815\n",
      "Early Stopping Counter: 2/5\n",
      "Epoch 13/50\n",
      "Train Loss: 0.0490, Train Accuracy: 0.9826\n",
      "Validation Loss: 0.1532, Validation Accuracy: 0.9560\n",
      "Validation Precision: 0.8684, Validation Recall: 0.9778\n",
      "Early Stopping Counter: 3/5\n",
      "Epoch 14/50\n",
      "Train Loss: 0.0598, Train Accuracy: 0.9799\n",
      "Validation Loss: 0.1978, Validation Accuracy: 0.9417\n",
      "Validation Precision: 0.8235, Validation Recall: 0.9852\n",
      "Early Stopping Counter: 4/5\n",
      "Epoch 15/50\n",
      "Train Loss: 0.0853, Train Accuracy: 0.9722\n",
      "Validation Loss: 0.1943, Validation Accuracy: 0.9532\n",
      "Validation Precision: 0.9825, Validation Recall: 0.8333\n",
      "Early Stopping Counter: 5/5\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Assume train_images_flat, val_images_flat, and their corresponding label tensors are provided\n",
    "# They were created using the flattening and tensor conversion logic\n",
    "\n",
    "\n",
    "\n",
    "# Labels are already in tensor form from the previous code\n",
    "train_labels_tensor = train_labels_tensors\n",
    "val_labels_tensor = val_labels_tensors\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "train_dataset = TensorDataset(train_images_flat, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_flat, val_labels_tensor)\n",
    "\n",
    "# Define the batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Model and device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Correcting the input dimensions to match the flattened image dimensions\n",
    "input_dim = train_images_tensor.shape[1]\n",
    "\n",
    "# Define the loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class or binary classification\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)  \n",
    "\n",
    "# Now the data is ready for training and validation\n",
    "\n",
    "# Function to calculate precision and recall\n",
    "def calculate_precision_recall(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Training function with Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0  # Count the number of epochs without improvement\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Training mode\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.long).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Compute metrics\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Calculate precision and recall on validation\n",
    "        val_precision, val_recall = calculate_precision_recall(model, val_loader, device)\n",
    "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Early Stopping: stop if no improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the model with the best validation loss\n",
    "            torch.save(model.state_dict(), \"best_model_v4.pth\")\n",
    "            print(\"Model saved!\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"Early Stopping Counter: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "        # If the number of epochs without improvement exceeds patience, stop\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Start training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7404\n",
      "Test Precision: 0.9286\n",
      "Test Recall: 0.3333\n",
      "Test F1-Score: 0.4906\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "#Convert them to tensors if they aren't already\n",
    "test_label_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "test_dataset = TensorDataset(test_images_flat, test_label_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            correct_preds += torch.sum(preds == target).item()\n",
    "            total_preds += target.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    precision, recall, f1, accuracy = calculate_metrics(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Define and initialize your model using initialize_kan_net\n",
    "input_width = 224 * 224\n",
    "model = initialize_kan_net(width=[input_width, 128, 64], seed=42, device=device)\n",
    "\n",
    "# Load the saved model state\n",
    "#model.load_state_dict(torch.load(\"best_model_v4.pth\"))\n",
    "#model.eval()\n",
    "\n",
    "# Load the saved state_dict\n",
    "state_dict = torch.load(\"best_model_v4.pth\", weights_only=True)\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# Print the state_dict keys of your current model\n",
    "current_state_dict = model.state_dict()\n",
    "#print(\"Current Model State Dict Keys:\", list(current_state_dict.keys()))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
